xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
par(mar = c(3, 3, 3, 3)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma1[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
par(mar = c(4, 4, 4, 4)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma1[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
par(mar = c(5, 4, 4, 4)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma1[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
par(mar = c(5, 5, 4, 4)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma1[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
par(mar = c(5, 5, 3, 3)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma1[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
par(mar = c(5, 5, 2, 2)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma1[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 1"))
points(beta_1, power_sigma1[2, ], pch = 20, col = "darkorange", cex = 1)
points(beta_1, power_sigma1[3, ], pch = 20, col = "red", cex = 1)
lines(beta_1, power_sigma1[1, ], col = "dodgerblue")
lines(beta_1, power_sigma1[2, ], col = "darkorange")
lines(beta_1, power_sigma1[3, ], col = "red")
legend("bottomright", c(expression(alpha ~ " = 0.01" ), expression(alpha ~ "= 0.05"), expression(alpha ~ "= 0.10")), lty = 1, lwd = 2,
col = c("dodgerblue", "darkorange", "red"), adj = c(0.2, 0.6))
par(mar = c(5, 5, 2, 2)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma2[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 2"))
points(beta_1, power_sigma2[2, ], pch = 20, col = "darkorange", cex = 1)
points(beta_1, power_sigma2[3, ], pch = 20, col = "red", cex = 1)
lines(beta_1, power_sigma2[1, ], col = "dodgerblue")
lines(beta_1, power_sigma2[2, ], col = "darkorange")
lines(beta_1, power_sigma2[3, ], col = "red")
legend("bottomright", c(expression(alpha ~ " = 0.01" ), expression(alpha ~ "= 0.05"), expression(alpha ~ "= 0.10")), lty = 1, lwd = 2,
col = c("dodgerblue", "darkorange", "red"), adj = c(0.2, 0.6))
par(mar = c(5, 5, 2, 2)) # adjusted plot margins, otherwise the "hat" does not display
plot(beta_1, power_sigma3[1, ], pch = 20, col = "dodgerblue", cex = 1,
xlab = expression(hat(beta)[1] ~ "values"),
ylab = expression(hat(Power)),
main = expression(hat(Power) ~ "for " ~ sigma ~ " = 4"))
points(beta_1, power_sigma3[2, ], pch = 20, col = "darkorange", cex = 1)
points(beta_1, power_sigma3[3, ], pch = 20, col = "red", cex = 1)
lines(beta_1, power_sigma3[1, ], col = "dodgerblue")
lines(beta_1, power_sigma3[2, ], col = "darkorange")
lines(beta_1, power_sigma3[3, ], col = "red")
legend("bottomright", c(expression(alpha ~ " = 0.01" ), expression(alpha ~ "= 0.05"), expression(alpha ~ "= 0.10")), lty = 1, lwd = 2,
col = c("dodgerblue", "darkorange", "red"), adj = c(0.2, 0.6))
install.packages(gfortran)
install.packages(gfortran)
library("zoo", lib.loc="~/R/R-3.4.0/library")
library("stats", lib.loc="~/R/R-3.4.0/library")
install.packages("C:\Users\a05v6zz\Downloads\lmtest_0.9-35.tar.gz")
install.packages("C://Users//a05v6zz//Downloads//lmtest_0.9-35.tar.gz")
source('~/.active-rstudio-document', echo=TRUE)
install.packages("car")
library(lmtest)
result1 = transformationsLog(predictor_variables[1], "Lifetime.Post.Consumers", fb_withResponseTransform$Lifetime.Post.Consumers, fb_withResponseTransform$Lifetime.Post.Consumers)
library(MASS)
library(readr)
library(lmtest)
library(car)
library(leaps)
library(knitr)
library(faraway)
library(tibble)
fb = read.table("dataset_Facebook.csv", sep = ";", header = T)
fb$Type           = as.factor(fb$Type)
fb$Category       = as.factor(fb$Category)
fb$Post.Month     = as.factor(fb$Post.Month)
fb$Post.Hour      = as.factor(fb$Post.Hour)
fb$Post.Weekday   = as.factor(fb$Post.Weekday)
fb$Paid           = as.factor(fb$Paid)
full_model = lm(Lifetime.Post.Consumers ~ ., data = fb)
colnames(fb)
typeLevels = levels(fb$Type)
summary(full_model)
fb$Total.Interactions = NULL
full_model = lm(Lifetime.Post.Consumers ~ ., data = fb)
summary(full_model)
nrow(fb)
#Cleansing Data
fb = fb[complete.cases(fb), ]
#Initial Analysis:
variables = colnames(fb)
predictor_variables = variables[which(variables != "Lifetime.Post.Consumers")]
response_variable = "Lifetime.Post.Consumers"
getAdditiveModels = function(variables, response_variable, data_set, alpha)
{
num_predictor_variables = length(variables)
p_val           = rep(0, num_predictor_variables ^ 2)
bp_p_value      = rep(0, num_predictor_variables ^ 2)
shapiro_p_value = rep(0, num_predictor_variables ^ 2)
strmodel        = rep(0, num_predictor_variables ^ 2)
rss             = rep(0, num_predictor_variables ^ 2)
beta_parameter  = rep(0, num_predictor_variables ^ 2)
pass_bp         = rep(0, num_predictor_variables ^ 2)
pass_shapiro    = rep(0, num_predictor_variables ^ 2)
adjustedR2      = rep(0, num_predictor_variables ^ 2)
sizeResiduals   = rep(0, num_predictor_variables ^ 2)
index = 1;
for (j in 1:num_predictor_variables)
{
smallestrss = 0
smallestrssIndex = 0
for (i in 1:length(variables))
{
if(j == 1) #at the beginning
{
startpointer          = index
#could make s1 be log(y)
s1                    = response_variable
s2                    = variables[i]
strmodel[index]       = paste(s1, " ~ " , s2)
}
else
{
s2                    = variables[i]
strmodel[index]       = paste(previousBestModel , " + " , s2)
}
model                    = lm(strmodel[index], data = data_set)
rss[index]               = sum(resid(model)^2)
bp_p_value[index]        = bptest(model)$p.value
shapiro_p_value[index]   = shapiro.test(resid(model))$p.value
beta_parameter[index]    = j
adjustedR2[index]        = summary(model)$adj.r.squared
sizeResiduals[index]     = length(resid(model))
if (sizeResiduals[i] == 0 )
{
print("ERROR!!!!!!!!!!!!!!!!!!!")
}
else
print(paste(strmodel[index], ": " , sizeResiduals[i]))
if (shapiro_p_value[i] > alpha) {
pass_shapiro[index] = TRUE
}
if (bp_p_value[i] > alpha) {
pass_bp[index] = TRUE
}
if (smallestrssIndex == 0 || rss[index] < smallestrss){
smallestrssIndex = index
smallestrss = rss[index]
}
index = index + 1
}
#for a given number of predictor variables create temp vector and find the min rss
previousBestModel = strmodel[smallestrssIndex]
}
result         = data.frame(beta_parameter, strmodel, rss, adjustedR2, bp_p_value, shapiro_p_value, pass_bp, pass_shapiro, sizeResiduals)
result$strmodel =  as.character(result$strmodel)
result
}
results = getAdditiveModels(predictor_variables, response_variable, fb, .05)
#here is a function that for a given number of beta parameters pulls out the lowest rss
getModels = function(results, num_predictor_variables){
bestModelForParamNumber = rep("", num_predictor_variables)
for (i in 1:num_predictor_variables)
{
subset_data = results[results$beta_parameter == i, ]
bestModelForParamNumber[i] = subset_data$strmodel[which.min(subset_data$rss)]
}
bestModelForParamNumber
}
bestModels = getModels(results, length(predictor_variables))
#now for each of the "best" linear models, do an anova test to determine which are actually the best
doAnova = function(dataset, models, alpha)
{
p_val   = rep(0, length(models) - 1)
keep_old = rep(FALSE, length(models) - 1)
winning_model = rep(0, length(models) - 1)
stop = FALSE
#print(length(models))
for (i in 1:(length(models) -1))
{
if (stop == FALSE)
{
p_val[i] = anova(lm(bestModels[i], data = dataset), lm(bestModels[i + 1], data = dataset))$"Pr(>F)"[2]
if (p_val[i] < alpha)
{
keep_old[i] = FALSE
winning_model[i] = bestModels[i + 1]
stop = FALSE
}
else
{
keep_old[i] = TRUE
winning_model[i] = bestModels[i]
stop = TRUE
report_winning  = winning_model[1:i]
report_p_val    = p_val[1:i]
report_keep_old = keep_old[1:i]
}
}
}
output = data.frame(report_winning, report_p_val, report_keep_old)
output$report_winning =  as.character(output$report_winning)
output
}
results = doAnova(fb, bestModels, 0.05 )
model_data_selected_RSS_Manual = results[results$report_keep_old == TRUE, ]
model_selected_RSS_Manual = lm(model_data_selected_RSS_Manual$report_winning, data = fb)
#best additive model based on RSS and Anova Test
#Lifetime.Post.Consumers  ~  Lifetime.Engaged.Users  +  like  +  share  +  Lifetime.People.who.have.liked.your.Page.and.engaged.with.your.post  +  Post.Month  +  Lifetime.Post.Consumptions  +  comment  +  Lifetime.Post.Total.Reach
###########################################################
#AIC and BIC
##########################################################
predictor_variables = variables[which(variables != "Lifetime.Post.Consumers")]
length(predictor_variables)
createStringFullModel = function(predictor_variables){
num_predictor_variables = length(predictor_variables)
for (i in 1:num_predictor_variables)
{
if (i == 1)
{
model = paste("Lifetime.Post.Consumers", "~" ,predictor_variables[i] )
print(model)
}
else
model = paste(model , " + " , predictor_variables[i])
}
model
}
strFullModel = createStringFullModel(predictor_variables)
##########################################################
#AIC - less aggressive
##########################################################
#forward AIC
fb_mod_start = lm(Lifetime.Post.Consumers ~ 1, data = fb)
model_forward_aic = step(fb_mod_start,
strFullModel,
direction = "forward", trace = 0)
summary(model_forward_aic)
vif(model_forward_aic)
fullMOdel = lm(strFullModel, data = fb)
model_back_aic = step(fullMOdel, direction = "backward", trace = 0)
summary(model_back_aic)
vif(model_back_aic)
##########################################################
#BIC - more aggressive
##########################################################
full_model = lm(Lifetime.Post.Consumers ~ ., data = fb)
n = length(resid(full_model))
model_forward_bic = step(fb_mod_start,
strFullModel,
direction = "forward", k = log(n), trace = 0)
summary(model_forward_bic)
vif(model_forward_bic)
#backward BIC
model_back_bic = step(full_model, direction = "backward", k = log(n), trace = 0)
summary(model_back_bic)
###########################################################
#Make a table saying which variables are in which model
#to specify which variables to explore
##########################################################
all = predictor_variables %in% names(coef(model_selected_RSS_Manual)) %in%  names(coef(model_forward_aic)) %in% names(coef(model_back_aic)) %in% names(coef(model_forward_bic))
Variables_RSS_Manual   = predictor_variables %in% names(coef(model_selected_RSS_Manual))
Variables_Forward_AIC  = predictor_variables %in% names(coef(model_forward_aic))
Variables_Backward_AIC = predictor_variables %in% names(coef(model_back_aic))
Variables_Forward_BIC  = predictor_variables %in% names(coef(model_forward_bic))
Variables_Backward_BIC = predictor_variables %in% names(coef(model_back_bic))
#Variable, RSS Evelaution per beta parameter, Backward BIC, Forward BIC, Backward AIC, Forward AIC
variables_for_analysis = data.frame(predictor_variables, Variables_RSS_Manual, Variables_Forward_BIC, Variables_Backward_BIC, Variables_Forward_AIC, Variables_Backward_AIC)
colnames(variables_for_analysis) = c("Variables" , "Variable included in RSS Manual", "Variable included in Forward BIC", "Variable included in Backward BIC", "Variable included in Forward AIC", "Variable included in Backward AIC")
knitr::kable(variables_for_analysis, caption = "MLR Additive Model Variable Analysis")
fb_subset = subset(fb, select = c("Lifetime.Post.Consumers", "Lifetime.Post.Total.Reach", "Lifetime.Engaged.Users", "Lifetime.Post.Consumptions", "Lifetime.People.who.have.liked.your.Page.and.engaged.with.your.post", "comment", "like", "share"))
pairs(fb_subset)
boxcox(model_selected_RSS_Manual, plotit = TRUE)
par(mfrow = c(2,2))
boxcox(model_forward_aic, plotit = TRUE)
boxcox(model_back_aic, plotit = TRUE)
boxcox(model_forward_bic, plotit = TRUE)
boxcox(model_back_bic, plotit = TRUE)
fb_subset = subset(fb, select = c("Lifetime.Post.Consumers", "Lifetime.Post.Total.Reach", "Lifetime.Engaged.Users", "Lifetime.Post.Consumptions", "Lifetime.People.who.have.liked.your.Page.and.engaged.with.your.post", "comment", "like", "share"))
log.Consumers = log(fb_subset$Lifetime.Post.Consumers)
fb_withResponseTransform = cbind( fb_subset, log.Consumers)
pairs(fb_withResponseTransform, col = "dodgerblue")
min(fb_withResponseTransform$Lifetime.Post.Total.Reach)
min(fb_withResponseTransform$Lifetime.Engaged.Users)
min(fb_withResponseTransform$Lifetime.Post.Consumptions)
min(fb_withResponseTransform$Lifetime.People.who.have.liked.your.Page.and.engaged.with.your.post)
min(fb_withResponseTransform$comment)
min(fb_withResponseTransform$like)
min(fb_withResponseTransform$share)
transformationsPowers = function(predictor, response, dataset, responsevector, predictorvector){
strQuad                      = paste("log(", response, ") ~ ", predictor , " + I(" , predictor, "^ 2) ")
quad_model                   = lm(strQuad, data = dataset)
quad_RMSE                    = sqrt(mean((responsevector - exp(fitted(quad_model))) ^ 2))
quad_bp_p_value              = bptest(quad_model)$p.value
quad_shapiro_p_value         = shapiro.test(resid(quad_model))$p.value
#  quad = c(quad_RMSE, quad_bp_p_value, quad_shapiro_p_value)
strThird                     = paste("log(", response, ") ~ ", predictor , " + I(" , predictor, "^ 2)  + I(", predictor, "^3)")
third_model                  = lm(strThird, data = dataset)
third_RMSE                   = sqrt(mean((responsevector - exp(fitted(third_model))) ^ 2))
third_bp_p_value             = bptest(third_model)$p.value
third_shapiro_p_value        = shapiro.test(resid(third_model))$p.value
#  third = c(third_RMSE, third_bp_p_value, third_shapiro_p_value)
#  result = data.frame(log = log, quad = quad, third = third)
predictor   = rep(predictor, 2)
transform   = c("^2 obeying hierachy", "^3 obeying hierachy")
bp          = c(quad_bp_p_value, third_bp_p_value)
shapiro     = c(quad_shapiro_p_value, third_shapiro_p_value)
RMSE        = c(quad_RMSE, third_RMSE)
data.frame(predictor = predictor, transform = transform, bp = bp, shapiro = shapiro, RMSE = RMSE)
}
variables = colnames(fb_withResponseTransform)
predictor_variables = variables[which((variables != "Lifetime.Post.Consumers") & variables != "log.Consumers")]
length(predictor_variables)
result1 = transformationsPowers(predictor_variables[1], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
result1 = transformationsPowers(predictor_variables[2], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
result1 = transformationsPowers(predictor_variables[3], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
result1 = transformationsPowers(predictor_variables[4], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
result1 = transformationsPowers(predictor_variables[5], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
result1 = transformationsPowers(predictor_variables[6], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
result1 = transformationsPowers(predictor_variables[7], "Lifetime.Post.Consumers", fb_withResponseTransform, fb_withResponseTransform$Lifetime.Post.Consumers)
knitr::kable(result1, caption = "Transformation Review")
transformationsLog = function (response, predictor, dataset){
strLog = paste("log(", response, ") ~ log(", predictor , ")")
print(strLog)
log_model = lm(strLog, data = dataset)
log_RMSE                     = sqrt(mean((responsevector - exp(fitted(log_model))) ^ 2))
log_bp_p_value               = bptest(log_model)$p.value
log_shapiro_p_value          = shapiro.test(resid(log_model))$p.value
log = c(log_RMSE, log_bp_p_value, log_shapiro_p_value)
}
fb_withResponseTransformForLog = fb_withResponseTransform
fb_withResponseTransformForLog$like = fb_withResponseTransformForLog$like + 1
fb_withResponseTransformForLog$share = fb_withResponseTransformForLog$share + 1
fb_withResponseTransformForLog$comment = fb_withResponseTransformForLog$comment + 1
result1 = transformationsLog("Lifetime.Post.Consumers", "Lifetime.Post.Total.Reach", fb_withResponseTransformForLog )
library("broom", lib.loc="~/R/R-3.2.5/library")
install.packages("DBI")
library(broom)
library("broom", lib.loc="~/R/R-3.2.5/library")
install.packages("assertthat")
library("broom", lib.loc="~/R/R-3.2.5/library")
library(broom)
glance(fit)
glance(model)
original_data <- read.csv("./data/dataset_Facebook.csv", header = TRUE, sep = ";")
complete_data <- original_data[complete.cases(original_data), ]
PostMonth11 = 1 * as.numeric(complete_data$Post.Month == "11")
complete_data$Category <- as.factor(complete_data$Category)
complete_data$Type <- as.factor(complete_data$Type)
complete_data$Post.Month <- as.factor(complete_data$Post.Month)
complete_data$Post.Hour <- as.factor(complete_data$Post.Hour)
complete_data$Post.Weekday <- as.factor(complete_data$Post.Weekday)
complete_data$Paid <- as.factor(complete_data$Paid)
complete_data = cbind(complete_data, PostMonth11)
complete_data$PostMonth11 <- as.factor(complete_data$PostMonth11)
set.seed(0)
test_indicies <- sample(1:nrow(complete_data), nrow(complete_data)/2)
train_data <- complete_data[-test_indicies,]
test_data <- complete_data[test_indicies,]
adj_training_data <- train_data
adj_training_data$comment <- adj_training_data$comment + 1
adj_training_data$like <- adj_training_data$like + 1
adj_training_data$share <- adj_training_data$share + 1
adj_testing_data <- test_data
adj_testing_data$comment <- adj_testing_data$comment + 1
adj_testing_data$like <- adj_testing_data$like + 1
adj_testing_data$share <- adj_testing_data$share + 1
model = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
Paid, data = adj_training_data)
setwd("~/University of Illinois/Status 420/Final Project/Analysis V3")
original_data <- read.csv("./data/dataset_Facebook.csv", header = TRUE, sep = ";")
complete_data <- original_data[complete.cases(original_data), ]
PostMonth11 = 1 * as.numeric(complete_data$Post.Month == "11")
complete_data$Type <- as.factor(complete_data$Type)
complete_data$Category <- as.factor(complete_data$Category)
complete_data$Post.Month <- as.factor(complete_data$Post.Month)
complete_data$Post.Hour <- as.factor(complete_data$Post.Hour)
complete_data$Post.Weekday <- as.factor(complete_data$Post.Weekday)
complete_data$Paid <- as.factor(complete_data$Paid)
complete_data = cbind(complete_data, PostMonth11)
complete_data$PostMonth11 <- as.factor(complete_data$PostMonth11)
set.seed(0)
test_indicies <- sample(1:nrow(complete_data), nrow(complete_data)/2)
train_data <- complete_data[-test_indicies,]
test_data <- complete_data[test_indicies,]
adj_training_data <- train_data
adj_training_data$comment <- adj_training_data$comment + 1
adj_training_data$like <- adj_training_data$like + 1
adj_training_data$share <- adj_training_data$share + 1
adj_testing_data <- test_data
adj_testing_data$comment <- adj_testing_data$comment + 1
adj_testing_data$like <- adj_testing_data$like + 1
adj_testing_data$share <- adj_testing_data$share + 1
model = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
Paid, data = adj_training_data)
summary(model)
bptest(model)
library(broom)
library(MASS)
library(readr)
library(lmtest)
library(car)
library(knitr)
library(faraway)
library(broom)
original_data <- read.csv("./data/dataset_Facebook.csv", header = TRUE, sep = ";")
complete_data <- original_data[complete.cases(original_data), ]
PostMonth11 = 1 * as.numeric(complete_data$Post.Month == "11")
complete_data$Type <- as.factor(complete_data$Type)
complete_data$Category <- as.factor(complete_data$Category)
complete_data$Post.Month <- as.factor(complete_data$Post.Month)
complete_data$Post.Hour <- as.factor(complete_data$Post.Hour)
complete_data$Post.Weekday <- as.factor(complete_data$Post.Weekday)
complete_data$Paid <- as.factor(complete_data$Paid)
complete_data = cbind(complete_data, PostMonth11)
set.seed(0)
test_indicies <- sample(1:nrow(complete_data), nrow(complete_data)/2)
train_data <- complete_data[-test_indicies,]
complete_data$PostMonth11 <- as.factor(complete_data$PostMonth11)
test_data <- complete_data[test_indicies,]
adj_training_data <- train_data
adj_training_data$comment <- adj_training_data$comment + 1
adj_training_data$like <- adj_training_data$like + 1
adj_training_data$share <- adj_training_data$share + 1
adj_testing_data <- test_data
adj_testing_data$comment <- adj_testing_data$comment + 1
adj_testing_data$like <- adj_testing_data$like + 1
adj_testing_data$share <- adj_testing_data$share + 1
model = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
Paid, data = adj_training_data)
summary(model)
bptest(model)
shapiro.test(resid(model))
complete_data = cbind(complete_data, PostMonth11)
model = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
Paid, data = adj_training_data)
hatvalues(model)
sum(hatvalues(model) > 2 * mean(hatvalues(model)))
sum(cooks.distance(model) > 4 / length(cooks.distance(model)))
model1 = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment), data = adj_testing_data)
model2 = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
Paid, data = adj_testing_data)
anova(model1, model2)
model3 = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment), data = adj_testing_data)
model4 = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
PostMonth11 , data = adj_testing_data)
anova(model3, model4)
bptest(model4)
shapiro.test(resid(model4))
model1 = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment), data = adj_testing_data)
model2 = lm(log(Lifetime.Post.Consumers) ~ like + log(like) + comment + log(comment) +
, data = adj_testing_data)
anova(model1, model2)
summary(model)$coefficients
m = lm(log(Lifetime.Post.Consumers) ~ Lifetime.Engaged.Users + like + share + Lifetime.People.who.have.liked.your.Page.and.engaged.with.your.post +
Post.Month + comment, data = adj_testing_data)
anova(m)$'Pr(>F)'[1]
glance(m)
anova(m)$'Pr(>F)'[1]
summary(m)
m_null = lm(log(Lifetime.Post.Consumers) ~ 1, data = adj_testing_data)
anova(m_null, m)
names(anova(m_null, m))
anova(m_null, m)$Pr(>F)
anova(m_null, m)$'Pr(>F)'
names(summary(m))
summary(m)$fstatistic
summary(m)$fstatistic[value]
summary(m)$fstatistic[1]
pf(summary(m)$fstatistic[1], 16, 230)
?pf
null_mpg_model = lm(mpg ~ wt + year, data = autompg)
full_mpg_model = lm(mpg ~ ., data = autompg)
anova(null_mpg_model, full_mpg_model)
null_mpg_model = lm(mpg ~ wt + year, data = autompg)
autompg = read.table(
"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data",
quote = "\"",
comment.char = "",
stringsAsFactors = FALSE)
colnames(autompg) = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year", "origin", "name")
autompg = subset(autompg, autompg$hp != "?")
autompg = subset(autompg, autompg$name != "plymouth reliant")
rownames(autompg) = paste(autompg$cyl, "cylinder", autompg$year, autompg$name)
autompg = subset(autompg, select = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year"))
autompg$hp = as.numeric(autompg$hp)
null_mpg_model = lm(mpg ~ wt + year, data = autompg)
full_mpg_model = lm(mpg ~ ., data = autompg)
anova(null_mpg_model, full_mpg_model)
anova(null_mpg_model, full_mpg_model)$`Pr(>F)'
anova(null_mpg_model, full_mpg_model)$'Pr(>F)'
anova(null_mpg_model, full_mpg_model)$'Pr(>F)'
anova(null_mpg_model, full_mpg_model)$"Pr(>F)"
names(anova(null_mpg_model, full_mpg_model))
5
shapiro.test(resid(model4))
